var documenterSearchIndex = {"docs":
[{"location":"man/Phasing_and_Imputation/#Preparing-Target-Data","page":"Phasing and Imputation","title":"Preparing Target Data","text":"","category":"section"},{"location":"man/Phasing_and_Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"MendelImpute accepts VCF, PLINK (.bed/.bim/.fam), and BGEN files.  Please make sure the following are true:","category":"page"},{"location":"man/Phasing_and_Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"Missing data is allowed. Genotypes does not have to be phased. \nVCF file ends in .vcf or .vcf.gz\nBGEN file ends in .bgen. If available, index files should have the same prefix. (e.g. genotypes.bgen should have index file called genotypes.bgen.bgi. Sample identifiers may be either contained in the .bgen file or listed in an external genotypes.sample file.\nFor PLINK files, all trios (.bim, .bed, .fam) are present in the same directory\nEach file contains only 1 (non-sex) chromosome\nEvery record (SNP) in the imputation target is present in the reference panel. If this is untrue, you must match markers in 2 VCF files. \nGiven a SNP, its CHROM, POS, REF, and  ALT fields are the same in target data and reference panel. MendelImpute use SNP position internally to align markers. \nThe position of every SNP is unique: so multiallelic markers should be excluded instead of split (this requirement will eventually be lifted). ","category":"page"},{"location":"man/Phasing_and_Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"note: Note\nCurrently only BGEN inputs support index files. Indexing support for VCF files coming soon...","category":"page"},{"location":"man/Phasing_and_Imputation/#Preparing-Reference-Haplotype-Panel","page":"Phasing and Imputation","title":"Preparing Reference Haplotype Panel","text":"","category":"section"},{"location":"man/Phasing_and_Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"Reference samples must be in VCF (.vcf or .vcf.gz) or BGEN (.bgen) format, every record must be phased, and contain no missing genotypes. Reference panels must be compressed into .jlso format first using the compress_haplotypes function. One must specify d: the maximum number of unique haplotypes per window. Larger d slows down computation, but increases accuracy. For most purposes, we recommend d approx 1000. ","category":"page"},{"location":"man/Phasing_and_Imputation/#Detailed-Example","page":"Phasing and Imputation","title":"Detailed Example","text":"","category":"section"},{"location":"man/Phasing_and_Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"We use the 1000 genomes chromosome 22 as an example. As show below, this data contains 424147 SNPs and 2504 samples.","category":"page"},{"location":"man/Phasing_and_Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"# load necessary packages in Julia\nusing VCFTools\nusing MendelImpute\nusing VCFTools\nusing Random\n\n# compute simple summary statistics\ndata = \"chr22.1kg.phase3.v5a.vcf.gz\"\n@show nrecords(data)\n@show nsamples(data);","category":"page"},{"location":"man/Phasing_and_Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"┌ Info: Precompiling MendelImpute [e47305d1-6a61-5370-bc5d-77554d143183]\n└ @ Base loading.jl:1317\n\n\nnrecords(data) = 424147\nnsamples(data) = 2504","category":"page"},{"location":"man/Phasing_and_Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"More summary statistics can be computed using the gtstats function in VCFTools.jl, with example usage here.","category":"page"},{"location":"man/Phasing_and_Imputation/#Step-1:-generating-realistic-reference-and-target-data","page":"Phasing and Imputation","title":"Step 1: generating realistic reference and target data","text":"","category":"section"},{"location":"man/Phasing_and_Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"First we generate a reference panel and imputation target based on the 1000 genomes data. Specifically, we divide the 1000 genomes chromosome 22 data so that ","category":"page"},{"location":"man/Phasing_and_Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"100 samples are randomly selected as imputation targets, where\n100k SNPs with minor allele frequency ge 005 are randomly selected to be the typed positions. \n0.1% of typed SNPs are masked (mimicking genotyping errors)\nGenotypes are unphased\nThe remaining 2404 samples are used as reference haplotypes. \nSNPs with duplicate positions are filtered out.\nAll multiallelic markers are filtered out.","category":"page"},{"location":"man/Phasing_and_Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"Instruction: execute the code below in a Julia session or a Jupyter notebook:","category":"page"},{"location":"man/Phasing_and_Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"# set random seed for reproducibility\nRandom.seed!(2020)\n\n# download example data \ndata = \"chr22.1kg.phase3.v5a.vcf.gz\"\nif !isfile(data) \n    download(\"http://bochet.gcc.biostat.washington.edu/beagle/1000_Genomes_phase3_v5a/b37.vcf/chr22.1kg.phase3.v5a.vcf.gz\")\nend\n\n# remove SNPs with the same positions, keep all samples, save result into new file\nSNPs_to_keep = .!find_duplicate_marker(data) \n@time VCFTools.filter(data, SNPs_to_keep, 1:nsamples(data), des = \"chr22.uniqueSNPs.vcf.gz\")\n\n# summarize data\ntotal_snps, samples, _, _, _, maf_by_record, _ = gtstats(\"chr22.uniqueSNPs.vcf.gz\")\n\n# generate target file with 100 samples and 100k snps with maf>0.05\nn = 100\np = 100000\nrecord_idx = falses(total_snps)\nlarge_maf = findall(x -> x > 0.05, maf_by_record)  \nRandom.shuffle!(large_maf)\nrecord_idx[large_maf[1:p]] .= true\nsample_idx = falses(samples)\nsample_idx[1:n] .= true\nRandom.shuffle!(sample_idx)\n@time VCFTools.filter(\"chr22.uniqueSNPs.vcf.gz\", record_idx, sample_idx, \n    des = \"target.chr22.typedOnly.vcf.gz\", allow_multiallelic=false)\n\n# unphase and mask 0.1% entries in target file\nmasks = falses(p, n)\nmissingprop = 0.001\nfor j in 1:n, i in 1:p\n    rand() < missingprop && (masks[i, j] = true)\nend\n@time mask_gt(\"target.chr22.typedOnly.vcf.gz\", masks, \n    des=\"target.chr22.typedOnly.masked.vcf.gz\", unphase=true)\n\n# generate target panel with all snps (this file contains true phase and genotypes)\n@time VCFTools.filter(\"chr22.uniqueSNPs.vcf.gz\", 1:total_snps, \n    sample_idx, des = \"target.chr22.full.vcf.gz\", allow_multiallelic=false)\n\n# generate reference panel with 2404 samples\n@time VCFTools.filter(\"chr22.uniqueSNPs.vcf.gz\", 1:total_snps, .!sample_idx, \n    des = \"ref.chr22.excludeTarget.vcf.gz\", allow_multiallelic=false)","category":"page"},{"location":"man/Phasing_and_Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"┌ Info: Precompiling MendelImpute [e47305d1-6a61-5370-bc5d-77554d143183]\n└ @ Base loading.jl:1278\n\u001b[32mfinding duplicate markers...100%|███████████████████████| Time: 0:03:56\u001b[39m\n\u001b[32mfiltering vcf file...100%|██████████████████████████████| Time: 0:04:46\u001b[39m\n\n\n292.131527 seconds (3.20 G allocations: 301.789 GiB, 7.89% gc time)\n\n\n\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:04:02\u001b[39m\n\u001b[32mfiltering vcf file...100%|██████████████████████████████| Time: 0:03:59\u001b[39m\n\n\n244.425505 seconds (3.18 G allocations: 301.694 GiB, 9.69% gc time)\n  1.935526 seconds (20.00 M allocations: 1.491 GiB, 6.33% gc time)\n\n\n\u001b[32mfiltering vcf file...100%|██████████████████████████████| Time: 0:04:10\u001b[39m\n\n\n255.505399 seconds (3.27 G allocations: 317.749 GiB, 9.95% gc time)\n\n\n\u001b[32mfiltering vcf file...100%|██████████████████████████████| Time: 0:07:27\u001b[39m\n\n\n453.383147 seconds (6.16 G allocations: 566.535 GiB, 10.16% gc time)","category":"page"},{"location":"man/Phasing_and_Imputation/#Output-explanation:","page":"Phasing and Imputation","title":"Output explanation:","text":"","category":"section"},{"location":"man/Phasing_and_Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"You just generated reference and target VCF files:","category":"page"},{"location":"man/Phasing_and_Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"ref.chr22.excludeTarget.vcf.gz: Reference haplotype panel with 2404 samples\ntarget.chr22.typedOnly.masked.vcf.gz: Imputation target file containing 100 samples at 100k SNPs. All genotypes are unphased and contains 0.1% missing data. ","category":"page"},{"location":"man/Phasing_and_Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"You also generated/downloaded:","category":"page"},{"location":"man/Phasing_and_Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"chr22.1kg.phase3.v5a.vcf.gz: The original chromosome 22 data downloaded from Beagle's website.\nchr22.uniqueSNPs.vcf.gz: This is the original chromosome 22 data excluding duplicate records (SNPs) by checking marker positions. The first SNP is included but all subsequent SNPs are removed. \ntarget.chr22.full.vcf.gz: The complete data for imputation target, used for checking imputation accuracy. All genotypes are phased and non-missing. \ntarget.chr22.typedOnly.vcf.gz: Complete target data on just the typed SNPs. All genotypes are phased and non-missing. Just by-producted for generating other files; not used for anything downstream.","category":"page"},{"location":"man/Phasing_and_Imputation/#Step-2:-generating-.jlso-compressed-reference-panel","page":"Phasing and Imputation","title":"Step 2: generating .jlso compressed reference panel","text":"","category":"section"},{"location":"man/Phasing_and_Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"MendelImpute requires one to pre-process the reference panel for faster reading. This is achieved via the compress_haplotypes function.","category":"page"},{"location":"man/Phasing_and_Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"# load necessary packages in Julia\nusing MendelImpute\n\nmax_d = 1000 # maximum number of unique haplotypes per window\nreffile = \"ref.chr22.excludeTarget.vcf.gz\"\ntgtfile = \"target.chr22.typedOnly.masked.vcf.gz\"\noutfile = \"ref.chr22.maxd1000.excludeTarget.jlso\"\n@time compress_haplotypes(reffile, tgtfile, outfile, max_d)","category":"page"},{"location":"man/Phasing_and_Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"\u001b[32mimporting reference data...100%|████████████████████████| Time: 0:02:00\u001b[39m\n\n\n295.546081 seconds (2.09 G allocations: 209.215 GiB, 10.53% gc time)","category":"page"},{"location":"man/Phasing_and_Imputation/#Step-3:-Run-imputation-and-phasing","page":"Phasing and Imputation","title":"Step 3: Run imputation and phasing","text":"","category":"section"},{"location":"man/Phasing_and_Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"The phase function will perform imputation and phasing. By default, all output genotypes will be phased and non-missing. A list of optional inputs can be found in the API.","category":"page"},{"location":"man/Phasing_and_Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"# note: run twice for more accurate timing\nreffile = \"ref.chr22.maxd1000.excludeTarget.jlso\" # jlso reference file\ntgtfile = \"target.chr22.typedOnly.masked.vcf.gz\"  # target genotype file\noutfile = \"mendel.imputed.chr22.vcf.gz\"           # output file name\nphase(tgtfile, reffile, outfile);","category":"page"},{"location":"man/Phasing_and_Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"Number of threads = 1\nImporting reference haplotype data...\n\n\n\u001b[32mComputing optimal haplotypes...100%|████████████████████| Time: 0:00:25\u001b[39m\n\u001b[32mPhasing...100%|█████████████████████████████████████████| Time: 0:00:05\u001b[39m\n\n\nTotal windows = 1634, averaging ~ 508 unique haplotypes per window.\n\nTimings: \n    Data import                     = 12.6331 seconds\n        import target data             = 3.54785 seconds\n        import compressed haplotypes   = 9.08523 seconds\n    Computing haplotype pair        = 25.8112 seconds\n        BLAS3 mul! to get M and N      = 1.14179 seconds per thread\n        haplopair search               = 19.8237 seconds per thread\n        initializing missing           = 0.11383 seconds per thread\n        allocating and viewing         = 0.183436 seconds per thread\n        index conversion               = 0.0146743 seconds per thread\n    Phasing by win-win intersection = 5.31061 seconds\n        Window-by-window intersection  = 0.56512 seconds per thread\n        Breakpoint search              = 3.4102 seconds per thread\n        Recording result               = 0.182498 seconds per thread\n    Imputation                     = 5.03281 seconds\n        Imputing missing               = 1.15402 seconds\n        Writing to file                = 3.87878 seconds\n\n    Total time                      = 48.9418 seconds","category":"page"},{"location":"man/Phasing_and_Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"The ; hides the output, or else the screen will be too jammed. ","category":"page"},{"location":"man/Phasing_and_Imputation/#Step-3.5:-(only-for-simulated-data)-check-imputation-accuracy","page":"Phasing and Imputation","title":"Step 3.5: (only for simulated data) check imputation accuracy","text":"","category":"section"},{"location":"man/Phasing_and_Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"Since we simulated data, we can check imputation accuracy.","category":"page"},{"location":"man/Phasing_and_Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"X_truth  = convert_gt(Float64, \"target.chr22.full.vcf.gz\")    # import true genotypes\nX_mendel = convert_gt(Float64, \"mendel.imputed.chr22.vcf.gz\") # import imputed genotypes\nn, p = size(X_mendel)\nprintln(\"error overall = \", sum(X_mendel .!= X_truth) / n / p)","category":"page"},{"location":"man/Phasing_and_Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"error overall = 0.005273994412137202","category":"page"},{"location":"man/Phasing_and_Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"Thus, we are looking at about 5 imputation error out of every 1000 SNPs. ","category":"page"},{"location":"man/Phasing_and_Imputation/#Post-imputation:-per-SNP-Imputation-Quality-Score","page":"Phasing and Imputation","title":"Post-imputation: per-SNP Imputation Quality Score","text":"","category":"section"},{"location":"man/Phasing_and_Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"Consider the observed genotype x_ij in 0 2 cup missing at SNP i of sample j and the corresponding imputed genotype g_ij derived from the two extended haplotypes of j. If S_i denotes the set of individuals with observed genotypes at the SNP, then MendelImpute's quality score q_i for the SNP is defined as","category":"page"},{"location":"man/Phasing_and_Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"q_i = 1 - frac1S_isum_j in S_i left(fracx_ij - g_ij2right)^2","category":"page"},{"location":"man/Phasing_and_Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"Note that 0 le q_i le 1 and that the larger the quality score, the more confidence in the imputed values. Because q_i can only be computed for the typed SNPs, an untyped SNP is assigned the average of the quality scores for its two closest flanking typed SNPs.","category":"page"},{"location":"man/Phasing_and_Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"To extract this score from a VCF file, one can do:","category":"page"},{"location":"man/Phasing_and_Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"using VariantCallFormat, Plots\nreader = VCF.Reader(openvcf(outfile, \"r\"))\nsnpscores = Vector{Float64}(undef, nrecords(outfile))\n\n# loop over SNPs\nfor (i, record) in enumerate(reader)\n    snpscores[i] = parse(Float64, VCF.info(record)[1].second)\nend\nclose(reader)\n\n# plot histogram of SNP scores\nhistogram(snpscores, label=:none, xlabel=\"per-SNP quality score\", \n    ylabel=\"SNP counts\", bins=30)","category":"page"},{"location":"man/Phasing_and_Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"(Image: svg)","category":"page"},{"location":"man/Phasing_and_Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"Conclusion: Most SNPs are well imputed (quality score close to 10), but a few have subpar quality score (e.g. below 0999). We recommend such SNPs to be filtered out. ","category":"page"},{"location":"man/Phasing_and_Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"note: Note\nThe popular correlation metric r^2 such as this one is NOT a good metric for measuring imputation accuracy under MendelImpute's model, because all imputed SNPs will have r^2 = 1. For details, please see our paper. ","category":"page"},{"location":"man/Phasing_and_Imputation/#Post-imputation:-per-sample-Imputation-Quality-score","page":"Phasing and Imputation","title":"Post-imputation: per-sample Imputation Quality score","text":"","category":"section"},{"location":"man/Phasing_and_Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"MendelImpute also computes a rough quality score (file ending in sample.error) for measuring how well each sample is imputed. This value is the sum of the least squares error for all typed SNPs scaled by the total number of observed SNPs, similar to the per-SNP quality score. A value of 1.0 is best, and 0 is worst. ","category":"page"},{"location":"man/Phasing_and_Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"using CSV, DataFrames\nquality = CSV.read(\"mendel.imputed.chr22.sample.error\", DataFrame) # import quality score \n\n# visualize error distribution\nhistogram(quality[:error], label=:none, xlabel=\"per-sample quality score\",\n    ylabel=\"Number of samples\") ","category":"page"},{"location":"man/Phasing_and_Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"(Image: svg)","category":"page"},{"location":"man/Phasing_and_Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"Conclusion: Most samples are well imputed (e.g. score close to 1), but some samples are indeed poorly imputed. From the histogram, we can safely filtered out samples with score  0999 as that would remove poorly imputed individuals without reducing sample size too much.","category":"page"},{"location":"man/script/#Run-MendelImpute-as-script","page":"Run as script","title":"Run MendelImpute as script","text":"","category":"section"},{"location":"man/script/","page":"Run as script","title":"Run as script","text":"If you don't want to run MendelImpute.jl in a Julia session (e.g. you want to run batch jobs on a cluster), you can do so by putting the code below in a Julia file. For example, in order to run with 8 threads, create a file called impute.jl which contains:","category":"page"},{"location":"man/script/","page":"Run as script","title":"Run as script","text":"# place these code in a file called impute.jl\nusing MendelImpute, VCFTools, LinearAlgebra\n\n# setup code goes here\nreffile = ARGS[1]       # first command line argument\ntgtfile = ARGS[2]       # second command line argument\noutfile = ARGS[3]       # third command line argument\nBLAS.set_num_threads(1) # set BLAS threads to 1 (see performance gotchas)\n\n# run MendelImpute with default options\nphase(tgtfile, reffile, outfile)","category":"page"},{"location":"man/script/","page":"Run as script","title":"Run as script","text":"Then in the terminal/command-prompt, you can do","category":"page"},{"location":"man/script/","page":"Run as script","title":"Run as script","text":"julia --threads 8 impute.jl ref.jlso target.vcf.gz output.vcf.gz","category":"page"},{"location":"man/painting/#Estimating-ancestry","page":"Estimating ancestry","title":"Estimating ancestry","text":"","category":"section"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"If samples in the reference haplotype panel are labeled with a population origin, MendelImpute can also be used for:","category":"page"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"Local ancestry inference (chromosome painting)\nGlobal ancestry inference ","category":"page"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"# first load all necessary packages\nusing MendelImpute\nusing StatsPlots","category":"page"},{"location":"man/painting/#Prepare-Example-data-for-illustration","page":"Estimating ancestry","title":"Prepare Example data for illustration","text":"","category":"section"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"We use the 1000 genomes chromosome 22 as illustration.  The original data is filtered into target and reference panels. Follow detailed example in Phasing and Imputation to obtain the same data.","category":"page"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"note: Note\nIn practice, it is better to infer ancestry of admixed populations using non-admixed reference populations. The example here is a simplified illustration and should not be taken too literally. ","category":"page"},{"location":"man/painting/#Process-each-sample's-population-origin","page":"Estimating ancestry","title":"Process each sample's population origin","text":"","category":"section"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"MendelImpute needs to know each reference sample's origin (country/ethnicity/region...etc). This origin information should be provided by the reference haplotype panel, but users are free to further organize origin labels base on their own criteria. For this purpose, MendelImpute needs a Dict{key, value} where each key is a reference sample ID and the value is the population code. Example dictionaries for 1000 genome project can be created by MendelImpute's internal helper functions. Users not using 1000 genomes would have to manually construct such a dictionary mapping reference sample IDs to a desired population label. ","category":"page"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"Here is a dictionary mapping sample IDs (from 1000 genomes project) to their super population codes.","category":"page"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"refID_to_superpopulation = thousand_genome_samples_to_super_population()","category":"page"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"Dict{String, String} with 2504 entries:\n  \"HG01791\" => \"EUR\"\n  \"HG02736\" => \"SAS\"\n  \"HG00182\" => \"EUR\"\n  \"HG03914\" => \"SAS\"\n  \"HG00149\" => \"EUR\"\n  \"NA12156\" => \"EUR\"\n  \"HG02642\" => \"AFR\"\n  \"HG02851\" => \"AFR\"\n  \"NA19835\" => \"AFR\"\n  \"NA19019\" => \"AFR\"\n  \"HG01131\" => \"AMR\"\n  \"HG03578\" => \"AFR\"\n  \"NA18550\" => \"EAS\"\n  \"HG02401\" => \"EAS\"\n  \"HG01350\" => \"AMR\"\n  \"HG03973\" => \"SAS\"\n  \"NA07000\" => \"EUR\"\n  \"HG01709\" => \"EUR\"\n  \"HG01395\" => \"AMR\"\n  \"HG01980\" => \"AMR\"\n  \"HG01979\" => \"AMR\"\n  \"HG01122\" => \"AMR\"\n  \"HG03869\" => \"SAS\"\n  \"HG03729\" => \"SAS\"\n  \"NA19920\" => \"AFR\"\n  ⋮         => ⋮","category":"page"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"Here is another dictionary mapping population code to super population codes. Thus we can map samples to super populations.","category":"page"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"pop_to_superpop = thousand_genome_population_to_superpopulation()","category":"page"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"Dict{String, String} with 26 entries:\n  \"CHS\" => \"EAS\"\n  \"CDX\" => \"EAS\"\n  \"GIH\" => \"SAS\"\n  \"MSL\" => \"AFR\"\n  \"KHV\" => \"EAS\"\n  \"PUR\" => \"AMR\"\n  \"ACB\" => \"AFR\"\n  \"CLM\" => \"AMR\"\n  \"FIN\" => \"EUR\"\n  \"TSI\" => \"EUR\"\n  \"BEB\" => \"SAS\"\n  \"LWK\" => \"AFR\"\n  \"STU\" => \"SAS\"\n  \"JPT\" => \"EAS\"\n  \"PJL\" => \"SAS\"\n  \"ITU\" => \"SAS\"\n  \"MXL\" => \"AMR\"\n  \"GWD\" => \"AFR\"\n  \"CEU\" => \"EUR\"\n  \"YRI\" => \"AFR\"\n  \"ASW\" => \"AFR\"\n  \"ESN\" => \"AFR\"\n  \"CHB\" => \"EAS\"\n  \"IBS\" => \"EUR\"\n  \"PEL\" => \"AMR\"\n  \"GBR\" => \"EUR\"","category":"page"},{"location":"man/painting/#Global-ancestry-inference","page":"Estimating ancestry","title":"Global ancestry inference","text":"","category":"section"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"Running global ancestry inference will produce a matrix Q where row i is the ancestry proportion of sample i. ","category":"page"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"tgtfile = \"target.chr22.typedOnly.masked.vcf.gz\"\nreffile = \"ref.chr22.maxd1000.excludeTarget.jlso\"\nsuperpopulations = unique(values(pop_to_superpop))\nQ = admixture_global(tgtfile, reffile, refID_to_superpopulation, superpopulations);","category":"page"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"Number of threads = 1\nImporting reference haplotype data...\n\n\n\u001b[32mComputing optimal haplotypes...100%|████████████████████| Time: 0:00:28\u001b[39m\n\u001b[32mPhasing...100%|█████████████████████████████████████████| Time: 0:00:05\u001b[39m\n\n\nTotal windows = 1634, averaging ~ 508 unique haplotypes per window.\n\nTimings: \n    Data import                     = 13.4081 seconds\n        import target data             = 4.22697 seconds\n        import compressed haplotypes   = 9.18115 seconds\n    Computing haplotype pair        = 28.9244 seconds\n        BLAS3 mul! to get M and N      = 1.17107 seconds per thread\n        haplopair search               = 22.3658 seconds per thread\n        initializing missing           = 0.123895 seconds per thread\n        allocating and viewing         = 0.225084 seconds per thread\n        index conversion               = 0.00800339 seconds per thread\n    Phasing by win-win intersection = 5.15749 seconds\n        Window-by-window intersection  = 0.577337 seconds per thread\n        Breakpoint search              = 3.25451 seconds per thread\n        Recording result               = 0.188439 seconds per thread\n    Imputation                     = 3.9812 seconds\n        Imputing missing               = 0.0254229 seconds\n        Writing to file                = 3.95578 seconds\n\n    Total time                      = 51.6225 seconds","category":"page"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"Each row of Q equals the sample's estimated ancestry (in %) from superpopulations[i]. For instance, sample 1 is 6% East Asian, 8% South Asian, 2% African, 16% American, and 65% European...etc.","category":"page"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"@show Q[1:10, :]; # sample 1~10 composition","category":"page"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"Q[1:10, :] = 10×5 DataFrame\n│ Row │ EAS       │ SAS       │ AFR        │ AMR       │ EUR      │\n│     │ Float64   │ Float64   │ Float64    │ Float64   │ Float64  │\n├─────┼───────────┼───────────┼────────────┼───────────┼──────────┤\n│ 1   │ 0.0681544 │ 0.0885727 │ 0.0226148  │ 0.16854   │ 0.652118 │\n│ 2   │ 0.073303  │ 0.0818105 │ 0.0164129  │ 0.0898631 │ 0.738611 │\n│ 3   │ 0.63185   │ 0.0973974 │ 0.00959202 │ 0.0729546 │ 0.188206 │\n│ 4   │ 0.687351  │ 0.0608572 │ 0.0101534  │ 0.0530236 │ 0.188614 │\n│ 5   │ 0.65251   │ 0.0811557 │ 0.010734   │ 0.0779404 │ 0.17766  │\n│ 6   │ 0.671986  │ 0.0712596 │ 0.00997388 │ 0.0715984 │ 0.175182 │\n│ 7   │ 0.103472  │ 0.0649164 │ 0.0136704  │ 0.425958  │ 0.391982 │\n│ 8   │ 0.0764429 │ 0.0729965 │ 0.0628898  │ 0.323463  │ 0.464208 │\n│ 9   │ 0.06995   │ 0.0772293 │ 0.0428307  │ 0.342301  │ 0.467689 │\n│ 10  │ 0.0644077 │ 0.0909931 │ 0.0358219  │ 0.293383  │ 0.515394 │","category":"page"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"We can visualize all samples's global admixture with a plot you might have seen elsewhere:","category":"page"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"global_plt = groupedbar(Matrix(Q), linecolor=nothing, bar_position = :stack,\n    label=[\"EUR\" \"SAS\" \"AFR\" \"AMR\" \"EAS\"], legend=:outerright, size=(1000, 150), dpi=300)\n\nsavefig(global_plt, \"global_admixture.png\")\ndisplay(\"image/png\", read(\"global_admixture.png\"))","category":"page"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"(Image: png)","category":"page"},{"location":"man/painting/#Local-ancestry-inference","page":"Estimating ancestry","title":"Local ancestry inference","text":"","category":"section"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"Now we turn to local ancestry inference, or chromosome painting. We still need to process each sample's population origin as detailed in the top of this page. The only difference is now you must additionally supply a color gradient for different populations manually. ","category":"page"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"note: Note\nThe plotting code here depends on StatsPlots.jl at version v0.14.17. If plotting doesn't work, try using Pkg;Pkg.pin(name=\"StatsPlots\", version=\"0.14.17\").","category":"page"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"# We pick our colors here: https://mdigi.tools/color-shades/#008000.\ncontinent = [\"SAS\", \"EAS\", \"EUR\", \"AMR\", \"AFR\"]\ncontinent_colors = [colorant\"#e6194B\", colorant\"#800000\", colorant\"#4363d8\", colorant\"#0000b3\", colorant\"#bfef45\"]\n\n# run MendelImpute to get local ancestries\ntgtfile = \"target.chr22.typedOnly.masked.vcf.gz\"\nreffile = \"ref.chr22.maxd1000.excludeTarget.jlso\"\nQ, pop_colors = admixture_local(tgtfile, reffile, refID_to_superpopulation, \n    continent, continent_colors);","category":"page"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"Number of threads = 1\nImporting reference haplotype data...\n\n\n\u001b[32mComputing optimal haplotypes...100%|████████████████████| Time: 0:00:24\u001b[39m\n\u001b[32mPhasing...100%|█████████████████████████████████████████| Time: 0:00:05\u001b[39m\n\n\nTotal windows = 1634, averaging ~ 508 unique haplotypes per window.\n\nTimings: \n    Data import                     = 8.32839 seconds\n        import target data             = 1.71787 seconds\n        import compressed haplotypes   = 6.61052 seconds\n    Computing haplotype pair        = 24.912 seconds\n        BLAS3 mul! to get M and N      = 1.27734 seconds per thread\n        haplopair search               = 23.2227 seconds per thread\n        initializing missing           = 0.136352 seconds per thread\n        allocating and viewing         = 0.238768 seconds per thread\n        index conversion               = 0.0202952 seconds per thread\n    Phasing by win-win intersection = 5.7508 seconds\n        Window-by-window intersection  = 0.88523 seconds per thread\n        Breakpoint search              = 4.53825 seconds per thread\n        Recording result               = 0.299743 seconds per thread\n    Imputation                     = 0.172601 seconds\n        Imputing missing               = 0.00086028 seconds\n        Writing to file                = 0.171741 seconds\n\n    Total time                      = 39.1647 seconds","category":"page"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"Lets plot the local ancestries of","category":"page"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"Samples 1 (British)\nSample 4 (Chinese)\nSample 84 (Kenyan)","category":"page"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"Their haplotypes occupy rows 1-2, 7-8, and 167-168 of Q, and their haplotype colors are stored in corresponding rows of pop_colors. ","category":"page"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"# sample index and axis labels\nsample_idx = [1, 2, 7, 8, 167, 168]\nsample_Q = Q[sample_idx, :]\nsample_color = pop_colors[sample_idx, :]\n\n# make plot\nxnames = [\"Sample 1 hap1\", \"Sample 1 hap2\", \"Sample 4 hap1\", \"Sample 4 hap2\", \"Sample 84 hap1\", \"Sample 84 hap2\"]\nynames = [\"SNP 1\", \"SNP 208k\", \"SNP 417k\"]\nlocal_plt = groupedbar(sample_Q, bar_position = :stack, bar_width=0.7, label=:none, \n    color=sample_color, xticks=(1:1:6, xnames), yticks=(0:0.5:1, ynames),\n    ytickfont=font(12), xtickfont=font(12), xrotation=20, grid=false, \n    right_margin = 30Plots.mm, linecolor=:match)\n\n# create a separate plot for legend\nxlength = length(continent)\nscatter!(local_plt, ones(xlength), collect(1:xlength), color=continent_colors, ytick=(1:xlength, continent), \n    xrange=(0.9, 1.1), xtick=false, label=:none, markersize=6, ytickfont=font(12),\n    grid=false, framestyle=:grid, mirror=true, tick_direction=:out, markershape=:rect,\n    inset = (1, bbox(-0.05, -0.1, 0.05, 1.1, :bottom, :right)), subplot = 2)\n\n# save figure\n# savefig(local_plt, \"local_admixture.png\")","category":"page"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"(Image: svg)","category":"page"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"Conclusion: ","category":"page"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"We can visualize the linkage patterns for the 3 samples across their 6 haplotypes\nSample 1 (British) is mostly European and admixed American, sample 2 (Chinese) is mainly South/East Asian, and sample 3 (Kenyan) is mainly African.","category":"page"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"For more details, please refer to our paper, or file an issue on GitHub. ","category":"page"},{"location":"man/ultra+compress/#Ultra-compressed-format","page":"Ultra compression","title":"Ultra-compressed format","text":"","category":"section"},{"location":"man/ultra+compress/","page":"Ultra compression","title":"Ultra compression","text":"One can optionally save/load ultra-compressed phased genotypes after imputation. Ultra-compression is nothing fancy. Instead of converting haplotype segments into genotypes, this protocol simply saves the starting position and the correct haplotype label. We put this result into our own data structure, and saving/loading is achieved by the JLSO package. ","category":"page"},{"location":"man/ultra+compress/#Saving","page":"Ultra compression","title":"Saving","text":"","category":"section"},{"location":"man/ultra+compress/","page":"Ultra compression","title":"Ultra compression","text":"Appending .jlso to the output file name will signal MendelImpute to save data in ultra-compressed format. For admixture estimation, we require one to save in .jlso format.","category":"page"},{"location":"man/ultra+compress/","page":"Ultra compression","title":"Ultra compression","text":"# first load all necessary packages\nusing MendelImpute\nusing VCFTools\n\n# compute each person's phase information\ntgtfile = \"target.chr22.typedOnly.masked.vcf.gz\"\nreffile = \"ref.chr22.maxd1000.excludeTarget.jlso\"\noutfile = \"mendel.imputed.jlso\" # output file name ends in jlso!\n@time phaseinfo = phase(tgtfile, reffile, outfile);","category":"page"},{"location":"man/ultra+compress/","page":"Ultra compression","title":"Ultra compression","text":"Number of threads = 1\nImporting reference haplotype data...\n\n\n\u001b[32mComputing optimal haplotypes...100%|████████████████████| Time: 0:00:23\u001b[39m\n\u001b[32mPhasing...100%|█████████████████████████████████████████| Time: 0:00:05\u001b[39m\n\n\nTotal windows = 1634, averaging ~ 508 unique haplotypes per window.\n\nTimings: \n    Data import                     = 13.5855 seconds\n        import target data             = 2.99557 seconds\n        import compressed haplotypes   = 10.5899 seconds\n    Computing haplotype pair        = 23.5138 seconds\n        BLAS3 mul! to get M and N      = 1.02228 seconds per thread\n        haplopair search               = 18.3673 seconds per thread\n        initializing missing           = 0.101495 seconds per thread\n        allocating and viewing         = 0.270367 seconds per thread\n        index conversion               = 0.0212053 seconds per thread\n    Phasing by win-win intersection = 5.17088 seconds\n        Window-by-window intersection  = 0.499549 seconds per thread\n        Breakpoint search              = 3.71212 seconds per thread\n        Recording result               = 0.00855205 seconds per thread\n    Imputation                     = 3.04347 seconds\n        Imputing missing               = 0.0513904 seconds\n        Writing to file                = 2.99208 seconds\n\n    Total time                      = 45.5041 seconds\n\n 60.231372 seconds (124.56 M allocations: 6.857 GiB, 5.31% gc time)","category":"page"},{"location":"man/ultra+compress/","page":"Ultra compression","title":"Ultra compression","text":"The object saved to mendel.imputed.jlso is literally the phaseinfo variable. We can inspect its element:","category":"page"},{"location":"man/ultra+compress/","page":"Ultra compression","title":"Ultra compression","text":"# look at sample 1's haplotype segments\nhaplotype_labels = phaseinfo[1].strand1.haplotypelabel # strand1\nhaplotype_start = phaseinfo[1].strand1.start # strand1\n[haplotype_start haplotype_labels]","category":"page"},{"location":"man/ultra+compress/","page":"Ultra compression","title":"Ultra compression","text":"545×2 Array{Int64,2}:\n      1  4119\n    236   887\n    423   272\n    622    12\n    741   124\n    792     4\n    824    24\n    944  1282\n   1116  1741\n   1202  4543\n   1691  1198\n   3031    22\n   3521    18\n      ⋮  \n 411702   877\n 412185    74\n 413733  3849\n 413868   248\n 414371    31\n 414552  3187\n 414989  4481\n 415807     5\n 415965   143\n 416352  1276\n 416744    71\n 417014   311","category":"page"},{"location":"man/ultra+compress/#Loading","page":"Ultra compression","title":"Loading","text":"","category":"section"},{"location":"man/ultra+compress/","page":"Ultra compression","title":"Ultra compression","text":"The function convert_compressed will load the ultra-compressed data into genotype matrices and the original phaseinfo data structure. ","category":"page"},{"location":"man/ultra+compress/","page":"Ultra compression","title":"Ultra compression","text":"Note: Decompressing requires loading the original haplotype reference panel. ","category":"page"},{"location":"man/ultra+compress/","page":"Ultra compression","title":"Ultra compression","text":"tgtfile = \"mendel.imputed.jlso\" # ultra-compressed genotypes after phasing & imputation\nreffile = \"ref.chr22.excludeTarget.vcf.gz\" # original haplotype reference file\nX1, X2, phaseinfo, sampleID, H = convert_compressed(Float64, tgtfile, reffile);","category":"page"},{"location":"man/ultra+compress/","page":"Ultra compression","title":"Ultra compression","text":"\u001b[32mimporting reference data...100%|████████████████████████| Time: 0:01:51\u001b[39m","category":"page"},{"location":"man/ultra+compress/","page":"Ultra compression","title":"Ultra compression","text":"Check this compression protocol exhibit same error rate with standard VCF compression. Note that X1, X2, and H are transposed. ","category":"page"},{"location":"man/ultra+compress/","page":"Ultra compression","title":"Ultra compression","text":"X_truth  = convert_gt(Float64, \"target.chr22.full.vcf.gz\") # import true genotypes\nX_mendel = (X1 + X2)' # transpose X1 and X2\nn, p = size(X_mendel)\nprintln(\"error overall = $(sum(X_mendel .!= X_truth) / n / p)\")","category":"page"},{"location":"man/ultra+compress/","page":"Ultra compression","title":"Ultra compression","text":"error overall = 0.00527504782243333","category":"page"},{"location":"man/performance/#Performance-gotchas","page":"Performance Gotchas","title":"Performance gotchas","text":"","category":"section"},{"location":"man/performance/#First-time-performance","page":"Performance Gotchas","title":"First time performance","text":"","category":"section"},{"location":"man/performance/","page":"Performance Gotchas","title":"Performance Gotchas","text":"In a fresh Julia session, the first time any function gets called will take a long time because the code has to be compiled on the spot. For instance, compare","category":"page"},{"location":"man/performance/","page":"Performance Gotchas","title":"Performance Gotchas","text":"@time using MendelImpute","category":"page"},{"location":"man/performance/","page":"Performance Gotchas","title":"Performance Gotchas","text":"  6.958706 seconds (16.72 M allocations: 1.148 GiB, 5.00% gc time)","category":"page"},{"location":"man/performance/","page":"Performance Gotchas","title":"Performance Gotchas","text":"@time using MendelImpute","category":"page"},{"location":"man/performance/","page":"Performance Gotchas","title":"Performance Gotchas","text":"  0.022658 seconds (32.81 k allocations: 1.886 MiB, 99.49% compilation time)","category":"page"},{"location":"man/performance/","page":"Performance Gotchas","title":"Performance Gotchas","text":"The first call was 350 times slower than the second time! Fortunately, for large problems, compilation time becomes negligible.","category":"page"},{"location":"man/performance/#Run-MendelImpute-in-parallel","page":"Performance Gotchas","title":"Run MendelImpute in parallel","text":"","category":"section"},{"location":"man/performance/","page":"Performance Gotchas","title":"Performance Gotchas","text":"If Julia is started with multiple threads (e.g. julia --threads 4), MendelImpute.jl will automatically run your code in parallel.","category":"page"},{"location":"man/performance/","page":"Performance Gotchas","title":"Performance Gotchas","text":"How to start Julia with multiple threads.\nExecute Threads.nthreads() within Julia to check if multiple thread is enabled\nSet the number of BLAS threads to be 1 by using LinearAlgebra; BLAS.set_num_threads(1). This avoids oversubscription. ","category":"page"},{"location":"man/performance/","page":"Performance Gotchas","title":"Performance Gotchas","text":"note: Note\nWe recommend number of threads equal to the number of physical CPU cores on your machine. Number of Julia threads should never exceed number of physical CPU cores!! Hyperthreading is valuable for I/O operations (in our experience), but not for linear algebra routines used throughout MendelImpute. ","category":"page"},{"location":"man/performance/#Compressing-haplotype-panels-is-slow","page":"Performance Gotchas","title":"Compressing haplotype panels is slow","text":"","category":"section"},{"location":"man/performance/","page":"Performance Gotchas","title":"Performance Gotchas","text":"Currently it is recommended to build a new compressed reference haplotype panel for every new set of typed SNPs (although this is not strictly required). The compression routine is slow because reading raw VCF files is slow. Thus, it is highly advised that one try to use the same set of typed SNPs as much as possible. ","category":"page"},{"location":"man/performance/","page":"Performance Gotchas","title":"Performance Gotchas","text":"We are actively developing a new set of functions in SnpArrays.jl to alleviate this problem. Since SnpArrays use memory mapping, read times can be improved dramatically. ","category":"page"},{"location":"man/performance/#max_d-too-high-(or-too-low)","page":"Performance Gotchas","title":"max_d too high (or too low)","text":"","category":"section"},{"location":"man/performance/","page":"Performance Gotchas","title":"Performance Gotchas","text":"When you compress the haplotype panels into a .jlso format, you specified max_d which is the maximum number of unique haplotypes per window. We generally recommend using max_d = 1000, BUT 1000 may be too small if you use a reference panel larger than HRC. In that case, you can try larger max_d, which will improve error rate. ","category":"page"},{"location":"man/performance/#Symptoms-for-max_d-too-high:","page":"Performance Gotchas","title":"Symptoms for max_d too high:","text":"","category":"section"},{"location":"man/performance/","page":"Performance Gotchas","title":"Performance Gotchas","text":"Computing optimal haplotypes is too slow. In particular, the timing for haplopair search is too high. ","category":"page"},{"location":"man/performance/#Symptoms-for-max_d-too-low:","page":"Performance Gotchas","title":"Symptoms for max_d too low:","text":"","category":"section"},{"location":"man/performance/","page":"Performance Gotchas","title":"Performance Gotchas","text":"Too few typed SNPs per window indicates max_d is set too low. You can calculate the number of typed SNPs per window by dividing the total number of SNPs in the target file by the total windows (a number that will be output after every run). Ideally you want an average of 400 typed SNPs per window, but something as low as 50 still works. Something like 10~20 is too low. ","category":"page"},{"location":"man/performance/#I-really-want-to-use-a-high-max_d","page":"Performance Gotchas","title":"I really want to use a high max_d","text":"","category":"section"},{"location":"man/performance/","page":"Performance Gotchas","title":"Performance Gotchas","text":"A high max_d generally improve error, so it is understandable you want to do so. If a high max_d value runs too slow, try setting stepwise = 100 and max_haplotypes to a number that is close to 1000. This avoids searching the global minimizer of the least-squares problem for windows that have more than max_haplotypes number of unique haplotypes. Setting thinning_factor instead of stepwise have a similar effect. Details for these 2 heuristic searches are explained in the appendix of our paper. ","category":"page"},{"location":"man/performance/#Do-you-have-enough-memory-(RAM)?","page":"Performance Gotchas","title":"Do you have enough memory (RAM)?","text":"","category":"section"},{"location":"man/performance/","page":"Performance Gotchas","title":"Performance Gotchas","text":"While MendelImpute uses the least RAM compared to competing softwares (as of 2020), it is still possible for large imputation problems to consume all available RAM. If this happens, Julia will first try to use swap before crashing (until all of swap is consumed). Monitor your RAM usage constantly to make sure this doesn't happen. On Mac/Linux machines, the top or htop command will monitor this information. Alternatively, the /usr/bin/time command will automatically records max RAM usage for job and whether any swap had been performed. ","category":"page"},{"location":"man/performance/#Rough-estimate-for-amount-of-RAM-needed","page":"Performance Gotchas","title":"Rough estimate for amount of RAM needed","text":"","category":"section"},{"location":"man/performance/","page":"Performance Gotchas","title":"Performance Gotchas","text":"There are 4 things that require lots of memory:","category":"page"},{"location":"man/performance/","page":"Performance Gotchas","title":"Performance Gotchas","text":"The target genotype matrix mathbfX_n times p requires n times p times 8 bits. If mathbfX is dosage data, then you need instead n times p times 32 bits\nThe matrix mathbfM_d times d requires c times d times d times 32 bits, where c is the number of parallel threads used and d is the number specified in the compress_haplotypes function.\nThe matrix mathbfN_n times d requires c times n times d times 32 bits, where c is the number of parallel threads used and d is the number specified in the compress_haplotypes function.\nThe compressed reference haplotype panel produced by the compress_haplotypes function. This typically requires about 3r gigabytes of RAM where r is your panel's size in .vcf.gz. ","category":"page"},{"location":"man/performance/","page":"Performance Gotchas","title":"Performance Gotchas","text":"If you do not have the above issues and your code is still running slow, file an issue on GitHub and we will take a look at it ASAP. ","category":"page"},{"location":"#MendelImpute.jl","page":"Home","title":"MendelImpute.jl","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Fast genotype imputation, phasing, and admixture estimation!","category":"page"},{"location":"","page":"Home","title":"Home","text":"MendelImpute.jl is the fastest and most memory-efficient software for phasing and genotype imputation, as of 2021. It is also capable of estimating local and global admixture coefficients using a reference haplotype panel.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Given a target genotype file (phased or unphased and may contain missing data) and a reference haplotype file (phased, no missing), our software imputes every SNP in the reference file to the target file, outputing phased or unphased genotypes. Like many other software, SNPs typed in target must all be present in the reference panel. ","category":"page"},{"location":"#Package-Features","page":"Home","title":"Package Features","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Phasing and imputation with respect to a reference haplotype panel\nImputation on dosage data, phasing without imputation, imputation without phasing\nBuilt-in support for VCF (.vcf, .vcf.gz), binary PLINK (.bed/.bim/.fam), and BGEN (.bgen) files\nOut-of-the-box multithreaded (shared memory) parallelism. \nAdmixture estimation, with code examples to make pretty plots!\nUltra-compressed file for phased genotypes.","category":"page"},{"location":"#Installation","page":"Home","title":"Installation","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Download and install Julia. Within Julia, copy and paste the following: ","category":"page"},{"location":"","page":"Home","title":"Home","text":"using Pkg\npkg\"add https://github.com/OpenMendel/SnpArrays.jl\"\npkg\"add https://github.com/OpenMendel/VCFTools.jl\"\npkg\"add https://github.com/OpenMendel/BGEN.jl\"\npkg\"add https://github.com/OpenMendel/MendelImpute.jl\"","category":"page"},{"location":"","page":"Home","title":"Home","text":"This package supports Julia v1.6+.","category":"page"},{"location":"#Manual-Outline","page":"Home","title":"Manual Outline","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Pages = [\n    \"man/Phasing_and_Imputation.md\"\n    \"man/performance.md\"\n    \"man/painting.md\"\n    \"man/ultra+compress.md\"\n    \"man/script.md\"\n    \"man/api.md\"\n]\nDepth = 2","category":"page"},{"location":"man/api/#API","page":"API","title":"API","text":"","category":"section"},{"location":"man/api/","page":"API","title":"API","text":"Documentation for MendelImpute.jl's functions.","category":"page"},{"location":"man/api/#Index","page":"API","title":"Index","text":"","category":"section"},{"location":"man/api/","page":"API","title":"API","text":"Pages = [\"api.md\"]","category":"page"},{"location":"man/api/#Functions","page":"API","title":"Functions","text":"","category":"section"},{"location":"man/api/","page":"API","title":"API","text":"phase\ncompress_haplotypes\nconvert_compressed\nadmixture_global\nadmixture_local\nthousand_genome_samples_to_population\nthousand_genome_samples_to_super_population\nthousand_genome_population_to_superpopulation","category":"page"},{"location":"man/api/#MendelImpute.phase","page":"API","title":"MendelImpute.phase","text":"phase(tgtfile::String, reffile::String, outfile::String; [impute::Bool],\n    [phase::Bool], [dosage::Bool], [rescreen::Bool], [max_haplotypes::Int], \n    [stepwise::Int], [thinning_factor::Int], [scale_allelefreq::Bool], \n    [dynamic_programming::Bool])\n\nMain function of MendelImpute program. Phasing (haplotying) of tgtfile from a pool of haplotypes reffile by sliding windows and saves result in outfile. All SNPs in tgtfile must be present in reffile. Per-SNP quality score will be saved in outfile, while per-sample imputation score will be saved in a file ending in sample.error.\n\nInput\n\ntgtfile: VCF, PLINK, or BGEN file. VCF files should end in .vcf or .vcf.gz.   PLINK files should exclude .bim/.bed/.fam trailings but the trio must all   be present in the same directory. BGEN files should end in .bgen\nreffile: Reference haplotype file ending in .jlso (compressed binary files).   See compress_haplotypes\noutfile: output filename ending in .vcf.gz, .vcf, or .jlso. VCF output   genotypes will have no missing data. If ending in .jlso, will output   ultra-compressed data structure recording HaplotypeMosaicPairs for    each sample.\n\nOptional Inputs\n\nimpute: If true, imputes every SNPs in reffile to tgtfile. Otherwise   only missing snps in tgtfile will be imputed.\nphase: If true, all output genotypes will be phased, but observed data    (minor allele count) may be changed. If phase=false all output genotypes   will be unphased but observed minor allele count will not change.\ndosage: If true, will assume target matrix are dosages for imputation. Note   this means the genotype matrix will be entirely single precision. \nrescreen: This option is more computationally intensive but gives more   accurate results. It saves a number of top haplotype pairs when solving   the least squares objective, and re-minimize least squares on just   observed data.\nmax_haplotypes: Maximum number of haplotypes for using global search. Windows   exceeding this number of unique haplotypes will be searched using a   heuristic. A non-zero stepscreen or thinning_factor need to be specified \nstepwise: If an integer is specified, will solve the least squares objective   by first finding stepwise top haplotypes using a stepwise heuristic then   finds the next haplotype using global search. Uses max_haplotypes. \nthinning_factor: If an integer is specified, will solve the least squares   objective on only thining_factor unique haplotypes. Uses max_haplotypes.\nscale_allelefreq: Boolean indicating whether to give rare SNPs more weight   scaled by wᵢ = 1 / √2p(1-p) where max weight is 2. \ndynamic_programming: Boolean indicating whether to phase with a global    search that finds the longest haplotype stretch over all windows. (Currently   broken, sorry!)\n\n\n\n\n\n","category":"function"},{"location":"man/api/#MendelImpute.compress_haplotypes","page":"API","title":"MendelImpute.compress_haplotypes","text":"compress_haplotypes(reffile::String, tgtfile::String, outfile::String, \n    [d::Int], [minwidth::Int], [overlap::Float64])\n\nCuts a haplotype matrix reffile into windows of variable width so that each window has less than d unique haplotypes. Saves result to outfile as a compressed binary format. All SNPs in tgtfile must be present in reffile.  All genotypes in reffile must be phased and non-missing, and all genotype positions must be unique. \n\nInputs\n\nreffile: reference haplotype file name (ends in .vcf, .vcf.gz, or .bgen)\ntgtfile: VCF, PLINK, or BGEN file. VCF files should end in .vcf or .vcf.gz.   PLINK files should exclude .bim/.bed/.fam suffixes but the trio must all   be present in the same directory. BGEN files should end in .bgen.\noutfile: Output file name (ends in .jlso)\n\nOptional Inputs\n\nd: Max number of unique haplotypes per genotype window (default d = 1000). \nminwidth: Minimum number of typed SNPs per window (default 0)\noverlap: How much overlap between adjacent genotype windows in percentage of   each window's width (default 0.0)\n\nWhy is tgtfile required?\n\nThe unique haplotypes in each window is computed on the typed SNPs only.  A genotype matrix tgtfile is used to identify the typed SNPs. In the future,  hopefully we can pre-compute compressed haplotype panels for all genotyping  platforms and provide them as downloadable files. But currently, users must run this function by themselves. \n\n\n\n\n\n","category":"function"},{"location":"man/api/#MendelImpute.convert_compressed","page":"API","title":"MendelImpute.convert_compressed","text":"convert_compressed(t<:Real, phaseinfo::String, reffile::String)\n\nConverts phaseinfo into a phased genotype matrix of type t using the full reference haplotype panel H \n\nInputs\n\nt: Type of matrix. If bool, genotypes are converted to a BitMatrix\nphaseinfo: Vector of HaplotypeMosaicPairs stored in .jlso format\nreffile: The complete (uncompressed) haplotype reference file\n\nOutput\n\nX1: allele 1 of the phased genotype. Each column is a sample. X = X1 + X2. \nX2: allele 2 of the phased genotype. Each column is a sample. X = X1 + X2. \nphase: the original data structure after phasing and imputation.\nsampleID: The ID's of each imputed person.  \nH: the complete reference haplotype panel. Columns of H are haplotypes.\n\n\n\n\n\nconvert_compressed(t<:Real, phaseinfo::Vector{HaplotypeMosaicPair}, H::AbstractMatrix)\n\nColumns of H are haplotypes.\n\n\n\n\n\n","category":"function"},{"location":"man/api/#MendelImpute.admixture_global","page":"API","title":"MendelImpute.admixture_global","text":"admixture_global(tgtfile::String, reffile::String, \n    refID_to_population::Dict{String, String}, populations::Vector{String})\n\nComputes global ancestry estimates for each sample in tgtfile using a labeled reference panel reffile. \n\nInputs\n\ntgtfile: VCF or PLINK files. VCF files should end in .vcf or .vcf.gz.   PLINK files should exclude .bim/.bed/.fam trailings but the trio must all   be present in the same directory.\nreffile: Reference haplotype file ending in .jlso (compressed binary files).   See compress_haplotypes.\nrefID_to_population: A dictionary mapping each sample IDs in the haplotype    reference panel to their population origin. For examples, see output of   thousand_genome_population_to_superpopulation and   thousand_genome_samples_to_super_population\npopulations: A vector of String containing unique populations present in   values(refID_to_population). \n\nOptional Inputs\n\nQ_outfile: Output file name for the estimated Q matrix. Default   Q_outfile=\"mendelimpute.ancestry.Q\".\nimputed_outfile: Output file name for the imputed genotypes ending in .jlso.   Default impute_outfile = \"mendelimpute.ancestry.Q.jlso\"\n\nOutput\n\nQ: A DataFrame containing estimated ancestry fractions. Each row is a sample.   Matrix will be saved in mendelimpute.ancestry.Q\n\n\n\n\n\n","category":"function"},{"location":"man/api/#MendelImpute.admixture_local","page":"API","title":"MendelImpute.admixture_local","text":"admixture_local(tgtfile::String, reffile::String, \n    refID_to_population::Dict{String, String}, populations::Vector{String},\n    population_colors::Vector{RGB{FixedPointNumbers.N0f8}})\n\nComputes global ancestry estimates for each sample in tgtfile using a labeled reference panel reffile. \n\nInputs\n\ntgtfile: VCF or PLINK files. VCF files should end in .vcf or .vcf.gz.   PLINK files should exclude .bim/.bed/.fam trailings but the trio must all   be present in the same directory.\nreffile: Reference haplotype file ending in .jlso (compressed binary files).   See compress_haplotypes.\nrefID_to_population: A dictionary mapping each sample IDs in the haplotype    reference panel to their population origin. For examples, see output of   thousand_genome_population_to_superpopulation and   thousand_genome_samples_to_super_population\npopulation: A list String containing unique populations present in   values(refID_to_population). \npopulation_colors: A vector of colors for each population.   typeof(population_colors} should be Vector{RGB{FixedPointNumbers.N0f8}}\n\nOutput\n\nQ: Matrix containing estimated ancestry fractions. Each row is a haplotype.   Sample 1's haplotypes are in rows 1 and 2, sample 2's are in rows 3, 4...etc.\npop_colors: Matrix with sample dimension of Q storing colors. \n\n\n\n\n\n","category":"function"},{"location":"man/api/#MendelImpute.thousand_genome_samples_to_population","page":"API","title":"MendelImpute.thousand_genome_samples_to_population","text":"thousand_genome_samples_to_population()\n\nCreates a dictionaries mapping sample IDs of 1000 genome project to 26 population codes.\n\nPopulation code and super population codes are described here: https://www.internationalgenome.org/category/population/\n\n\n\n\n\n","category":"function"},{"location":"man/api/#MendelImpute.thousand_genome_samples_to_super_population","page":"API","title":"MendelImpute.thousand_genome_samples_to_super_population","text":"thousand_genome_samples_to_population()\n\nCreates a dictionaries mapping sample IDs of 1000 genome project to 5 super population codes.\n\nPopulation code and super population codes are described here: https://www.internationalgenome.org/category/population/\n\n\n\n\n\n","category":"function"},{"location":"man/api/#MendelImpute.thousand_genome_population_to_superpopulation","page":"API","title":"MendelImpute.thousand_genome_population_to_superpopulation","text":"thousand_genome_population_to_superpopulation()\n\nCreates a dictionary mapping population codes of 1000 genome project to their super-population codes.\n\nPopulation code and super population codes are described here: https://www.internationalgenome.org/category/population/\n\n\n\n\n\n","category":"function"}]
}
